name: Data quality report
inputs:
- {name: dataset_dir, type: String}
- {name: dataset_type, type: String, default: df, optional: true}
- {name: ref_dataset_dir, type: String, optional: true}
- {name: additional_args, type: JsonObject, optional: true}
- {name: column_mapping, type: JsonObject, optional: true}
outputs:
- {name: output_dir, type: String}
- {name: mlpipeline_ui_metadata, type: String}
implementation:
  container:
    image: quay.io/ibm/kubeflow-notebook-image-ppc64le:latest
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'evidently==0.2.0' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install
      --quiet --no-warn-script-location 'evidently==0.2.0' --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def _make_parent_dirs_and_return_path(file_path: str):
          import os
          os.makedirs(os.path.dirname(file_path), exist_ok=True)
          return file_path

      def data_quality_report(
          dataset_dir,
          output_dir,
          mlpipeline_ui_metadata_path,
          dataset_type = 'df',
          ref_dataset_dir = None,
          additional_args = None,
          column_mapping = None

      ):

          import pandas as pd
          import os
          import json
          from evidently.metric_preset import DataQualityPreset
          from evidently.report import Report
          from pathlib import Path

          def _process_dataframe(dataset, opt_args=None):
              return pd.read_pickle(dataset, **opt_args)

          def _process_csv(dataset, opt_args=None):
              return pd.read_csv(dataset, **opt_args)

          def _process_huggingface(dataset, opt_args=None):
              return pd.DataFrame(dataset, **opt_args)

          DATA_TYPES = {
              'df': _process_dataframe,
              'csv': _process_csv,
              'huggingface': _process_huggingface
          }

          def process_dataset(dataset, args=None):
              if dataset is None:
                  return None
              return DATA_TYPES[dataset_type.lower()](dataset, (args or {}))

          df = process_dataset(dataset_dir, args=additional_args)
          ref_data = process_dataset(ref_dataset_dir, args=additional_args)

          report = Report(metrics=[
              DataQualityPreset()
          ])

          report.run(current_data=df, reference_data=ref_data, column_mapping=column_mapping)

          Path(output_dir).parent.mkdir(parents=True, exist_ok=True)
          report.save_html(output_dir)

          html = os.path.abspath(output_dir)
          html_content = open(html, 'r').read()

          metadata = {
              'outputs' : [{
              'type': 'web-app',
              'storage': 'inline',
              'source': html_content,
              }]
          }

          with open(mlpipeline_ui_metadata_path, 'w') as f:
              json.dump(metadata, f)

      import json
      import argparse
      _parser = argparse.ArgumentParser(prog='Data quality report', description='')
      _parser.add_argument("--dataset-dir", dest="dataset_dir", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--dataset-type", dest="dataset_type", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--ref-dataset-dir", dest="ref_dataset_dir", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--additional-args", dest="additional_args", type=json.loads, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--column-mapping", dest="column_mapping", type=json.loads, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--output-dir", dest="output_dir", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--mlpipeline-ui-metadata", dest="mlpipeline_ui_metadata_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parsed_args = vars(_parser.parse_args())

      _outputs = data_quality_report(**_parsed_args)
    args:
    - --dataset-dir
    - {inputPath: dataset_dir}
    - if:
        cond: {isPresent: dataset_type}
        then:
        - --dataset-type
        - {inputValue: dataset_type}
    - if:
        cond: {isPresent: ref_dataset_dir}
        then:
        - --ref-dataset-dir
        - {inputPath: ref_dataset_dir}
    - if:
        cond: {isPresent: additional_args}
        then:
        - --additional-args
        - {inputValue: additional_args}
    - if:
        cond: {isPresent: column_mapping}
        then:
        - --column-mapping
        - {inputValue: column_mapping}
    - --output-dir
    - {outputPath: output_dir}
    - --mlpipeline-ui-metadata
    - {outputPath: mlpipeline_ui_metadata}
